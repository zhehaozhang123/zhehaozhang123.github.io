---
layout: paper
id: angler
categories: papers
permalink: papers/angler
title: "Angler: Helping Machine Translation Practitioners Prioritize Model Improvements"
authors: 
  - Samantha Robertson
  - Zijie J. Wang
  - Dominik Moritz
  - Mary Beth Kery
  - Fred Hohman
equal-contribution:
  - Samantha Robertson
  - Zijie J. Wang
venue: ACM Conference on Human Factors in Computing Systems
venue-shorthand: CHI
location: Hamburg, Germany
year: 2023
url: /papers/angler
pdf: https://machinelearning.apple.com/research/helping-machine-translation
# preview: 
recording: https://www.youtube.com/watch?v=69bD4k0v390
code: https://github.com/apple/ml-translate-vis
demo: https://apple.github.io/ml-translate-vis
selected: false
type: conference
doi: 10.1145/3544548.3580790
figure: /images/papers/23-angler-chi.png
featured: false
feature-order: 1
feature-title: Angler
feature-description: Helping machine translation practitioners prioritize model improvements
image: /images/featured/angler.png
coming-soon: false


bibtex: |-

  @inproceedings{robertson2023angler,
    title={Angler: Helping Machine Translation Practitioners Prioritize Model Improvements},
    author={Robertson, Samantha and Wang, Zijie J. and Moritz, Dominik and Kery, Mary Beth and Hohman, Fred},
    booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
    year={2023},
    organization={ACM},
    doi={10.1145/3544548.3580790}
  }
---

Machine learning (ML) models can fail in unexpected ways in the real world, but not all model failures are equal.
With finite time and resources, ML practitioners are forced to prioritize their model debugging and improvement efforts.
Through interviews with 13 ML practitioners at Apple, we found that practitioners construct small targeted test sets to estimate an error's nature, scope, and impact on users.
We built on this insight in a case study with machine translation models, and developed Angler, an interactive visual analytics tool to help practitioners prioritize model improvements.
In a user study with 7 machine translation experts, we used Angler to understand prioritization practices when the input space is infinite, and obtaining reliable signals of model quality is expensive.
Our study revealed that participants could form more interesting and user-focused hypotheses for prioritization by analyzing quantitative summary statistics and qualitatively assessing data by reading sentences.
